{
    "simlator": {
        "number_of_samples": 2000,
        "input_channels": "Dev1/ai0:4",
        "sens_cofficients": [
            22.984,
            23.261,
            22.85,
            35.801,
            25.222
        ],
        "plasma_actuator_csv": "../csv/PA120-2.csv",
        "sample_rate": 200000,
        "reward_channel": 4,
        "gain": 900,
        "actions": [
            [
                100,
                3
            ],
            [
                600,
                3
            ]
        ],
        "number_average": 10,
        "burst_frequnecy": 600,
        "base_frequency": 12000,
        "output_channel": "Dev1/ao0",
        "reward_indicator": -0.55,
        "state_channels": [
            0,
            3,
            4
        ],
        "dynamic_pressure": 57,
        "unit_change": 1000000,
        "timeout": 2,
        "nb_actions": 2,
        "total_time": 1,
        "voltage": 3
    },
    "agent": {
        "rescaling_epsilon": 0.001,
        "remote_memory_warmup_size": 100,
        "per_beta_steps": 50000,
        "input_sequence": 10,
        "test_dir": "../output/test/",
        "overlap_length": 10,
        "enable_image_layer": true,
        "gamma": 0.99,
        "burnin_length": 20,
        "print_interval": 80,
        "num_actors": 1,
        "action_interval": 1,
        "lstm_units_num": 64,
        "remote_memory_capacity": 3000,
        "per_enable_is": false,
        "actor_log": "Output_Actor.txt",
        "dense_units_num": 64,
        "test_number": 5,
        "remote_memory_type": "per_proportional",
        "metrics": [],
        "target_model_update": 500,
        "per_beta_initial": 0,
        "dueling_network_type": "ave",
        "priority_exponent": 0.9,
        "epsilon": 0.6,
        "per_alpha": 0.6,
        "batch_size": 16,
        "local_memory_update_size": 10,
        "no_op_steps": 50,
        "enable_double_dqn": true,
        "training_number": 5,
        "enable_rescaling_priority": false,
        "input_shape": [
            10,
            3
        ],
        "save_weights_path": "r2d2_image_lstm.h5",
        "sequence_length": 30,
        "enable_noisynet": false,
        "learner_log": "Output_Learner.txt",
        "epsilon_alpha": 2,
        "log_dir": "../output/",
        "load_weights_path": "r2d2_image_lstm.h5",
        "enable_dueling_network": true,
        "actor_model_sync_interval": 400,
        "enable_rescaling_train": false,
        "test": true,
        "multireward_steps": 3,
        "save_overwrite": true
    }
}